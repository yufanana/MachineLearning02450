{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "d4e78eeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import matplotlib.pylab as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sklearn.linear_model as lm\n",
    "from sklearn import model_selection\n",
    "from toolbox_02450 import draw_neural_net"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "099f613a",
   "metadata": {},
   "source": [
    "### One-hot-encoding for categorical attributes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "bb30417b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>workingday</th>\n",
       "      <th>temp</th>\n",
       "      <th>atemp</th>\n",
       "      <th>hum</th>\n",
       "      <th>windspeed</th>\n",
       "      <th>cnt</th>\n",
       "      <th>season_1</th>\n",
       "      <th>season_2</th>\n",
       "      <th>season_3</th>\n",
       "      <th>weathersit_1</th>\n",
       "      <th>weathersit_2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.344167</td>\n",
       "      <td>0.363625</td>\n",
       "      <td>0.805833</td>\n",
       "      <td>0.160446</td>\n",
       "      <td>985</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0.363478</td>\n",
       "      <td>0.353739</td>\n",
       "      <td>0.696087</td>\n",
       "      <td>0.248539</td>\n",
       "      <td>801</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0.196364</td>\n",
       "      <td>0.189405</td>\n",
       "      <td>0.437273</td>\n",
       "      <td>0.248309</td>\n",
       "      <td>1349</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.212122</td>\n",
       "      <td>0.590435</td>\n",
       "      <td>0.160296</td>\n",
       "      <td>1562</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>0.226957</td>\n",
       "      <td>0.229270</td>\n",
       "      <td>0.436957</td>\n",
       "      <td>0.186900</td>\n",
       "      <td>1600</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>726</th>\n",
       "      <td>1</td>\n",
       "      <td>0.254167</td>\n",
       "      <td>0.226642</td>\n",
       "      <td>0.652917</td>\n",
       "      <td>0.350133</td>\n",
       "      <td>2114</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>727</th>\n",
       "      <td>1</td>\n",
       "      <td>0.253333</td>\n",
       "      <td>0.255046</td>\n",
       "      <td>0.590000</td>\n",
       "      <td>0.155471</td>\n",
       "      <td>3095</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>728</th>\n",
       "      <td>0</td>\n",
       "      <td>0.253333</td>\n",
       "      <td>0.242400</td>\n",
       "      <td>0.752917</td>\n",
       "      <td>0.124383</td>\n",
       "      <td>1341</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>729</th>\n",
       "      <td>0</td>\n",
       "      <td>0.255833</td>\n",
       "      <td>0.231700</td>\n",
       "      <td>0.483333</td>\n",
       "      <td>0.350754</td>\n",
       "      <td>1796</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>730</th>\n",
       "      <td>1</td>\n",
       "      <td>0.215833</td>\n",
       "      <td>0.223487</td>\n",
       "      <td>0.577500</td>\n",
       "      <td>0.154846</td>\n",
       "      <td>2729</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>731 rows Ã— 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     workingday      temp     atemp       hum  windspeed   cnt  season_1  \\\n",
       "0             0  0.344167  0.363625  0.805833   0.160446   985         1   \n",
       "1             0  0.363478  0.353739  0.696087   0.248539   801         1   \n",
       "2             1  0.196364  0.189405  0.437273   0.248309  1349         1   \n",
       "3             1  0.200000  0.212122  0.590435   0.160296  1562         1   \n",
       "4             1  0.226957  0.229270  0.436957   0.186900  1600         1   \n",
       "..          ...       ...       ...       ...        ...   ...       ...   \n",
       "726           1  0.254167  0.226642  0.652917   0.350133  2114         1   \n",
       "727           1  0.253333  0.255046  0.590000   0.155471  3095         1   \n",
       "728           0  0.253333  0.242400  0.752917   0.124383  1341         1   \n",
       "729           0  0.255833  0.231700  0.483333   0.350754  1796         1   \n",
       "730           1  0.215833  0.223487  0.577500   0.154846  2729         1   \n",
       "\n",
       "     season_2  season_3  weathersit_1  weathersit_2  \n",
       "0           0         0             0             1  \n",
       "1           0         0             0             1  \n",
       "2           0         0             1             0  \n",
       "3           0         0             1             0  \n",
       "4           0         0             1             0  \n",
       "..        ...       ...           ...           ...  \n",
       "726         0         0             0             1  \n",
       "727         0         0             0             1  \n",
       "728         0         0             0             1  \n",
       "729         0         0             1             0  \n",
       "730         0         0             0             1  \n",
       "\n",
       "[731 rows x 11 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Read file and store as pandas dataframe\n",
    "filename = '../Data/day.csv'\n",
    "df = pd.read_csv(filename)\n",
    "\n",
    "for attribute in ['instant','dteday','yr','mnth','holiday','weekday','casual','registered']:\n",
    "    df = df.drop(attribute, axis=1)\n",
    "    \n",
    "# One hot encoding\n",
    "ohe_df = pd.get_dummies(df, columns = ['season','weathersit'])\n",
    "ohe_df = ohe_df.drop(['season_4','weathersit_3'], axis=1)    # season_4, weathersit_3 are chosen as reference variables\n",
    "display(ohe_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb0d36af",
   "metadata": {},
   "source": [
    "### Standardize data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "e5cbb7f4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>workingday</th>\n",
       "      <th>temp</th>\n",
       "      <th>atemp</th>\n",
       "      <th>hum</th>\n",
       "      <th>windspeed</th>\n",
       "      <th>cnt</th>\n",
       "      <th>season_1</th>\n",
       "      <th>season_2</th>\n",
       "      <th>season_3</th>\n",
       "      <th>weathersit_1</th>\n",
       "      <th>weathersit_2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.826662</td>\n",
       "      <td>-0.679946</td>\n",
       "      <td>1.250171</td>\n",
       "      <td>-0.387892</td>\n",
       "      <td>-1.817953</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.721095</td>\n",
       "      <td>-0.740652</td>\n",
       "      <td>0.479113</td>\n",
       "      <td>0.749602</td>\n",
       "      <td>-1.912999</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.634657</td>\n",
       "      <td>-1.749767</td>\n",
       "      <td>-1.339274</td>\n",
       "      <td>0.746632</td>\n",
       "      <td>-1.629925</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.614780</td>\n",
       "      <td>-1.610270</td>\n",
       "      <td>-0.263182</td>\n",
       "      <td>-0.389829</td>\n",
       "      <td>-1.519898</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.467414</td>\n",
       "      <td>-1.504971</td>\n",
       "      <td>-1.341494</td>\n",
       "      <td>-0.046307</td>\n",
       "      <td>-1.500269</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>726</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.318665</td>\n",
       "      <td>-1.521108</td>\n",
       "      <td>0.175807</td>\n",
       "      <td>2.061426</td>\n",
       "      <td>-1.234757</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>727</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.323224</td>\n",
       "      <td>-1.346690</td>\n",
       "      <td>-0.266238</td>\n",
       "      <td>-0.452131</td>\n",
       "      <td>-0.728012</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>728</th>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.323224</td>\n",
       "      <td>-1.424344</td>\n",
       "      <td>0.878392</td>\n",
       "      <td>-0.853552</td>\n",
       "      <td>-1.634057</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>729</th>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.309558</td>\n",
       "      <td>-1.490049</td>\n",
       "      <td>-1.015664</td>\n",
       "      <td>2.069444</td>\n",
       "      <td>-1.399023</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>730</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.528225</td>\n",
       "      <td>-1.540482</td>\n",
       "      <td>-0.354061</td>\n",
       "      <td>-0.460201</td>\n",
       "      <td>-0.917073</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>731 rows Ã— 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     workingday      temp     atemp       hum  windspeed       cnt  season_1  \\\n",
       "0           0.0 -0.826662 -0.679946  1.250171  -0.387892 -1.817953       1.0   \n",
       "1           0.0 -0.721095 -0.740652  0.479113   0.749602 -1.912999       1.0   \n",
       "2           1.0 -1.634657 -1.749767 -1.339274   0.746632 -1.629925       1.0   \n",
       "3           1.0 -1.614780 -1.610270 -0.263182  -0.389829 -1.519898       1.0   \n",
       "4           1.0 -1.467414 -1.504971 -1.341494  -0.046307 -1.500269       1.0   \n",
       "..          ...       ...       ...       ...        ...       ...       ...   \n",
       "726         1.0 -1.318665 -1.521108  0.175807   2.061426 -1.234757       1.0   \n",
       "727         1.0 -1.323224 -1.346690 -0.266238  -0.452131 -0.728012       1.0   \n",
       "728         0.0 -1.323224 -1.424344  0.878392  -0.853552 -1.634057       1.0   \n",
       "729         0.0 -1.309558 -1.490049 -1.015664   2.069444 -1.399023       1.0   \n",
       "730         1.0 -1.528225 -1.540482 -0.354061  -0.460201 -0.917073       1.0   \n",
       "\n",
       "     season_2  season_3  weathersit_1  weathersit_2  \n",
       "0         0.0       0.0           0.0           1.0  \n",
       "1         0.0       0.0           0.0           1.0  \n",
       "2         0.0       0.0           1.0           0.0  \n",
       "3         0.0       0.0           1.0           0.0  \n",
       "4         0.0       0.0           1.0           0.0  \n",
       "..        ...       ...           ...           ...  \n",
       "726       0.0       0.0           0.0           1.0  \n",
       "727       0.0       0.0           0.0           1.0  \n",
       "728       0.0       0.0           0.0           1.0  \n",
       "729       0.0       0.0           1.0           0.0  \n",
       "730       0.0       0.0           0.0           1.0  \n",
       "\n",
       "[731 rows x 11 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "N, M = ohe_df.shape\n",
    "attribute_names = list(ohe_df.columns)\n",
    "\n",
    "# Get column indexes\n",
    "temp_col = ohe_df.columns.get_loc(\"temp\")\n",
    "atemp_col = ohe_df.columns.get_loc(\"atemp\")\n",
    "hum_col = ohe_df.columns.get_loc(\"hum\")\n",
    "wspd_col = ohe_df.columns.get_loc(\"windspeed\")\n",
    "cnt_col = ohe_df.columns.get_loc(\"cnt\")\n",
    "\n",
    "# Undo the original max-min normalization\n",
    "data = ohe_df.values\n",
    "for row in range(0, N):\n",
    "    data[row, temp_col] = data[row, temp_col]*(39-(-8)) + (-8)\n",
    "    data[row, atemp_col] = data[row, atemp_col]*(50-(-16)) + (-16)\n",
    "    data[row, hum_col] = data[row, hum_col]*100\n",
    "    data[row, wspd_col] = data[row, wspd_col]*67\n",
    "\n",
    "# Standarize ratio data attributes\n",
    "for col in range(temp_col, cnt_col+1): # subtract mean column-wise\n",
    "    mn = data[:, col].mean(0)\n",
    "    std = np.std(data[:, col])\n",
    "    data[:, col] = (data[:, col] - np.ones(N)*mn)/std\n",
    "\n",
    "# Create DataFrame for visualisation\n",
    "data_df = pd.DataFrame(data, columns=attribute_names)\n",
    "display(data_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce5ab082",
   "metadata": {},
   "source": [
    "### Set 'cnt' as target variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "7066153f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "N: 731, M: 11 (including offset)\n"
     ]
    }
   ],
   "source": [
    "# Split dataset into features and target vector\n",
    "cnt_col = attribute_names.index(\"cnt\")\n",
    "y = data[:,cnt_col]\n",
    "X = np.delete(data, cnt_col, axis=1)\n",
    "attribute_names.pop(cnt_col)\n",
    "N, M = X.shape\n",
    "\n",
    "# Add offset attribute\n",
    "X = np.concatenate((np.ones((X.shape[0],1)),X),1)\n",
    "attribute_names = [u'offset']+attribute_names\n",
    "M = M+1\n",
    "\n",
    "print(\"N: {}, M: {} (including offset)\".format(N,M))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "a74c263b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['offset',\n",
       " 'workingday',\n",
       " 'temp',\n",
       " 'atemp',\n",
       " 'hum',\n",
       " 'windspeed',\n",
       " 'season_1',\n",
       " 'season_2',\n",
       " 'season_3',\n",
       " 'weathersit_1',\n",
       " 'weathersit_2']"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "attribute_names"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75170046",
   "metadata": {},
   "source": [
    "### 1. Regularized Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "d2b6d907",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Values of lambda\n",
    "lambdas = np.power(10.,np.linspace(-5,9,100))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a8f2d57",
   "metadata": {},
   "source": [
    "### 2. Artificial Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "b80d9cff",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model of type:\n",
      "\n",
      "Sequential(\n",
      "  (0): Linear(in_features=11, out_features=2, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=2, out_features=1, bias=True)\n",
      ")\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Define the ANN model structure\n",
    "h_values = [2,4]\n",
    "n_replicates = 1        # number of networks trained in each k-fold\n",
    "max_iter = 15000\n",
    "\n",
    "model = lambda n_hidden_units: torch.nn.Sequential(\n",
    "                    torch.nn.Linear(M, n_hidden_units), #M features to H hiden units\n",
    "                    # 1st transfer function, either Tanh or ReLU:\n",
    "                    torch.nn.Tanh(),                            #torch.nn.ReLU()   \n",
    "                    torch.nn.Linear(n_hidden_units, 1) # H hidden units to 1 output neuron\n",
    "                    )\n",
    "\n",
    "loss_fn = torch.nn.MSELoss()\n",
    "print('Training model of type:\\n\\n{}\\n'.format(str(model(h_values[0]))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "fd851d35",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_neural_net(model, h, loss_fn, X, y,\n",
    "                     n_replicates=3, max_iter=10000, tolerance=1e-6):\n",
    "    \"\"\"\n",
    "    Train a neural network with PyTorch based on a training set consisting of\n",
    "    observations X and class y. The model and loss_fn inputs define the\n",
    "    architecture to train and the cost-function update the weights based on,\n",
    "    respectively.\n",
    "        \n",
    "    Args:\n",
    "        model:          A function handle to make a torch.nn.Sequential.\n",
    "        loss_fn:        A torch.nn-loss, e.g.  torch.nn.BCELoss() for binary \n",
    "                        binary classification, torch.nn.CrossEntropyLoss() for\n",
    "                        multiclass classification, or torch.nn.MSELoss() for\n",
    "                        regression (see https://pytorch.org/docs/stable/nn.html#loss-functions)\n",
    "        n_replicates:   An integer specifying number of replicates to train,\n",
    "                        the neural network with the lowest loss is returned.\n",
    "        max_iter:       An integer specifying the maximum number of iterations\n",
    "                        to do (default 10000).\n",
    "        tolerenace:     A float describing the tolerance/convergence criterion\n",
    "                        for minimum relative change in loss (default 1e-6)\n",
    "                        \n",
    "        \n",
    "    Returns:\n",
    "        A list of three elements:\n",
    "            best_net:       A trained torch.nn.Sequential that had the lowest \n",
    "                            loss of the trained replicates\n",
    "            final_loss:     An float specifying the loss of best performing net\n",
    "            learning_curve: A list containing the learning curve of the best net.\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    import torch\n",
    "    # Specify maximum number of iterations for training\n",
    "    logging_frequency = 1000 # display the loss every 1000th iteration\n",
    "    best_final_loss = 1e100\n",
    "    print('\\n\\tTraining ANN with h={} hidden units'.format(h))\n",
    "    \n",
    "    for r in range(n_replicates):\n",
    "        print('\\n\\tReplicate: {}/{}'.format(r+1, n_replicates))\n",
    "        # Make a new net (calling model() makes a new initialization of weights) \n",
    "        net = model(h)\n",
    "        \n",
    "        # initialize weights based on limits that scale with number of in- and\n",
    "        # outputs to the layer, increasing the chance that we converge to \n",
    "        # a good solution\n",
    "        torch.nn.init.xavier_uniform_(net[0].weight)\n",
    "        torch.nn.init.xavier_uniform_(net[2].weight)\n",
    "                     \n",
    "        # We can optimize the weights by means of stochastic gradient descent\n",
    "        # The learning rate, lr, can be adjusted if training doesn't perform as\n",
    "        # intended try reducing the lr. If the learning curve hasn't converged\n",
    "        # (i.e. \"flattend out\"), you can try try increasing the maximum number of\n",
    "        # iterations, but also potentially increasing the learning rate:\n",
    "        #optimizer = torch.optim.SGD(net.parameters(), lr = 5e-3)\n",
    "        \n",
    "        # A more complicated optimizer is the Adam-algortihm, which is an extension\n",
    "        # of SGD to adaptively change the learing rate, which is widely used:\n",
    "        optimizer = torch.optim.Adam(net.parameters())\n",
    "        \n",
    "        # Train the network while displaying and storing the loss\n",
    "        print('\\t\\t{}\\t{}\\t\\t\\t{}'.format('Iter', 'Loss','Rel. loss'))\n",
    "        learning_curve = [] # setup storage for loss at each step\n",
    "        old_loss = 1e6\n",
    "        for i in range(max_iter):\n",
    "            y_est = net(X) # forward pass, predict labels on training set\n",
    "            loss = loss_fn(y_est, y) # determine loss\n",
    "            loss_value = loss.data.numpy() #get numpy array instead of tensor\n",
    "            learning_curve.append(loss_value) # record loss for later display\n",
    "            \n",
    "            # Convergence check, see if the percentual loss decrease is within\n",
    "            # tolerance:\n",
    "            p_delta_loss = np.abs(loss_value-old_loss)/old_loss\n",
    "            if p_delta_loss < tolerance: break\n",
    "            old_loss = loss_value\n",
    "            \n",
    "            # display loss with some frequency:\n",
    "            if (i != 0) & ((i+1) % logging_frequency == 0):\n",
    "                print_str = '\\t\\t' + str(i+1) + '\\t' + str(loss_value) + '\\t' + str(p_delta_loss)\n",
    "                print(print_str)\n",
    "            # do backpropagation of loss and optimize weights \n",
    "            optimizer.zero_grad(); loss.backward(); optimizer.step()\n",
    "            \n",
    "            \n",
    "        # display final loss\n",
    "        print('\\t\\tFinal loss:')\n",
    "        print_str = '\\t\\t' + str(i+1) + '\\t' + str(loss_value) + '\\t' + str(p_delta_loss)\n",
    "        print(print_str)\n",
    "        \n",
    "        if loss_value < best_final_loss: \n",
    "            best_net = net\n",
    "            best_final_loss = loss_value\n",
    "            best_learning_curve = learning_curve\n",
    "        \n",
    "    # Return the best curve along with its final loss and learing curve\n",
    "    return best_net, best_final_loss, best_learning_curve"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a89e582",
   "metadata": {},
   "source": [
    "### Cross Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "1ba99068",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cross validation\n",
    "K_outer = 3\n",
    "K_inner = 3\n",
    "\n",
    "cv_outer = model_selection.KFold(K_outer, shuffle=False)\n",
    "cv_inner = model_selection.KFold(K_inner, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "b8d1f9fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize variables\n",
    "Error_par_lr = np.empty((K_outer,1))\n",
    "Error_test_lr = np.empty((K_outer,1))\n",
    "Error_par_rlr = np.empty((K_outer,1))\n",
    "Error_test_rlr = np.empty((K_outer,1))\n",
    "Error_par_nofeatures = np.empty((K_outer,1))\n",
    "Error_test_nofeatures = np.empty((K_outer,1))\n",
    "Error_test_ANN = np.zeros((K_outer,1))\n",
    "\n",
    "opt_h_values = np.zeros((K_outer,1))            # optimal ANN hidden units for each outer fold\n",
    "opt_lambdas = np.empty((K_outer,1))             # optimal lambdas for each outer fold\n",
    "w_rlr = np.empty((M,K_outer))                   # weights for each attribute with regularisation\n",
    "w_noreg = np.empty((M,K_outer))                 # weights for each attribute without regularisation\n",
    "mu = np.empty((K_outer, M-1))\n",
    "sigma = np.empty((K_outer, M-1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df0a66ba",
   "metadata": {},
   "source": [
    "### Training and Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "f103a176",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Outer Cross Validation Fold: 1/3\n",
      "\n",
      "\tInner Fold: 1/3\n",
      "\n",
      "\tReplicate: 1/1\n",
      "\t\tIter\tLoss\t\t\tRel. loss\n",
      "\t\t1000\t0.16743736\t0.00026896084\n",
      "\t\t2000\t0.15027599\t7.0893395e-05\n",
      "\t\t3000\t0.1269628\t0.00017930364\n",
      "\t\t4000\t0.11796054\t3.1137715e-05\n",
      "\t\t5000\t0.11534121\t1.5761176e-05\n",
      "\t\t6000\t0.11394771\t9.8731825e-06\n",
      "\t\t7000\t0.1129763\t7.188299e-06\n",
      "\t\t8000\t0.11231424\t4.51089e-06\n",
      "\t\t9000\t0.11189406\t3.1961188e-06\n",
      "\t\t10000\t0.11161881\t1.8022528e-06\n",
      "\t\tFinal loss:\n",
      "\t\t10871\t0.111472495\t9.3572885e-07\n",
      "\n",
      "\tBest loss: 0.11147249490022659\n",
      "\n",
      "\n",
      "\tReplicate: 1/1\n",
      "\t\tIter\tLoss\t\t\tRel. loss\n",
      "\t\t1000\t0.122692816\t0.00023926188\n",
      "\t\t2000\t0.10590202\t0.00011740625\n",
      "\t\t3000\t0.095879465\t0.00010085453\n",
      "\t\t4000\t0.08850993\t4.6969064e-05\n",
      "\t\t5000\t0.085836455\t2.2046645e-05\n",
      "\t\t6000\t0.08436378\t1.0862617e-05\n",
      "\t\t7000\t0.08374187\t5.3382187e-06\n",
      "\t\tFinal loss:\n",
      "\t\t7168\t0.083668426\t2.6714676e-07\n",
      "\n",
      "\tBest loss: 0.08366842567920685\n",
      "\n",
      "\n",
      "\tInner Fold: 2/3\n",
      "\n",
      "\tReplicate: 1/1\n",
      "\t\tIter\tLoss\t\t\tRel. loss\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\yufan\\AppData\\Local\\Temp\\ipykernel_3836\\2114972505.py:41: RuntimeWarning: invalid value encountered in divide\n",
      "  X_train[:, 1:] = (X_train[:, 1:] - mu[k_in, :] ) / sigma[k_in, :]\n",
      "C:\\Users\\yufan\\AppData\\Local\\Temp\\ipykernel_3836\\2114972505.py:42: RuntimeWarning: divide by zero encountered in divide\n",
      "  X_val[:, 1:] = (X_val[:, 1:] - mu[k_in, :] ) / sigma[k_in, :]\n",
      "C:\\Users\\yufan\\AppData\\Local\\Temp\\ipykernel_3836\\2114972505.py:42: RuntimeWarning: invalid value encountered in divide\n",
      "  X_val[:, 1:] = (X_val[:, 1:] - mu[k_in, :] ) / sigma[k_in, :]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t\t1000\t0.32744503\t0.00024413291\n",
      "\t\t2000\t0.28967738\t4.8248898e-05\n",
      "\t\t3000\t0.28279418\t1.327836e-05\n",
      "\t\t4000\t0.27931577\t1.2483463e-05\n",
      "\t\t5000\t0.27366394\t4.0182917e-05\n",
      "\t\t6000\t0.26610923\t1.2207068e-05\n",
      "\t\t7000\t0.2628228\t1.7802417e-05\n",
      "\t\t8000\t0.2568187\t2.506492e-05\n",
      "\t\t9000\t0.25075215\t2.1155158e-05\n",
      "\t\t10000\t0.24686533\t1.0140629e-05\n",
      "\t\tFinal loss:\n",
      "\t\t10716\t0.24543792\t9.106874e-07\n",
      "\n",
      "\tBest loss: 0.24543792009353638\n",
      "\n",
      "\n",
      "\tReplicate: 1/1\n",
      "\t\tIter\tLoss\t\t\tRel. loss\n",
      "\t\t1000\t0.30647346\t0.00020115478\n",
      "\t\t2000\t0.27015322\t7.920088e-05\n",
      "\t\t3000\t0.2531102\t5.3453125e-05\n",
      "\t\t4000\t0.2407736\t4.987979e-05\n",
      "\t\t5000\t0.23009747\t3.9955456e-05\n",
      "\t\t6000\t0.22380197\t1.8775745e-05\n",
      "\t\t7000\t0.2201951\t1.4211031e-05\n",
      "\t\t8000\t0.21716909\t1.4957951e-05\n",
      "\t\t9000\t0.21365985\t1.5622065e-05\n",
      "\t\t10000\t0.21090192\t1.1021974e-05\n",
      "\t\t11000\t0.20881775\t8.4203675e-06\n",
      "\t\t12000\t0.20753664\t4.3079904e-06\n",
      "\t\t13000\t0.2067982\t3.0263652e-06\n",
      "\t\t14000\t0.20625147\t2.1674214e-06\n",
      "\t\t15000\t0.20579748\t2.3894227e-06\n",
      "\t\tFinal loss:\n",
      "\t\t15000\t0.20579748\t2.3894227e-06\n",
      "\n",
      "\tBest loss: 0.205797478556633\n",
      "\n",
      "\n",
      "\tInner Fold: 3/3\n",
      "\n",
      "\tReplicate: 1/1\n",
      "\t\tIter\tLoss\t\t\tRel. loss\n",
      "\t\t1000\t0.13440286\t0.0008494243\n",
      "\t\t2000\t0.09115481\t0.00020249948\n",
      "\t\t3000\t0.0790166\t8.551492e-05\n",
      "\t\t4000\t0.07493261\t3.34075e-05\n",
      "\t\t5000\t0.0729903\t2.2558357e-05\n",
      "\t\t6000\t0.071183756\t4.0609095e-05\n",
      "\t\t7000\t0.06726762\t2.7467797e-05\n",
      "\t\t8000\t0.05732518\t0.00016646445\n",
      "\t\t9000\t0.0537842\t2.112497e-05\n",
      "\t\t10000\t0.05299927\t1.1246188e-05\n",
      "\t\t11000\t0.052454505\t9.942624e-06\n",
      "\t\t12000\t0.05186679\t1.3718233e-05\n",
      "\t\t13000\t0.05083762\t2.45476e-05\n",
      "\t\t14000\t0.049918447\t1.1417881e-05\n",
      "\t\t15000\t0.049565535\t3.6827716e-06\n",
      "\t\tFinal loss:\n",
      "\t\t15000\t0.049565535\t3.6827716e-06\n",
      "\n",
      "\tBest loss: 0.04956553503870964\n",
      "\n",
      "\n",
      "\tReplicate: 1/1\n",
      "\t\tIter\tLoss\t\t\tRel. loss\n",
      "\t\t1000\t0.07528917\t0.00024971148\n",
      "\t\t2000\t0.062671244\t0.0001364597\n",
      "\t\t3000\t0.05605878\t9.448765e-05\n",
      "\t\t4000\t0.052639417\t3.7011327e-05\n",
      "\t\t5000\t0.05117295\t2.6716167e-05\n",
      "\t\t6000\t0.049071122\t7.052112e-05\n",
      "\t\t7000\t0.044784337\t7.6106546e-05\n",
      "\t\t8000\t0.042433567\t3.651977e-05\n",
      "\t\tFinal loss:\n",
      "\t\t8890\t0.041292436\t9.021725e-08\n",
      "\n",
      "\tBest loss: 0.04129243642091751\n",
      "\n",
      "\tRetraining ANN using optimal number of hidden units\n",
      "\n",
      "\tReplicate: 1/1\n",
      "\t\tIter\tLoss\t\t\tRel. loss\n",
      "\t\t1000\t0.2884108\t4.8874066e-05\n",
      "\t\t2000\t0.2783269\t3.4691642e-05\n",
      "\t\t3000\t0.27084482\t2.475719e-05\n",
      "\t\t4000\t0.2663665\t1.0628928e-05\n",
      "\t\t5000\t0.26389146\t8.018251e-06\n",
      "\t\t6000\t0.26217592\t5.3426024e-06\n",
      "\t\t7000\t0.26105666\t3.4247992e-06\n",
      "\t\t8000\t0.26033852\t2.0605507e-06\n",
      "\t\tFinal loss:\n",
      "\t\t8927\t0.25992423\t9.17261e-07\n",
      "\n",
      "\tTest Error for Outer Fold 1/3\n",
      "\n",
      "\t\tRLR: 0.9660000205039978\n",
      "\n",
      "\t\tANN: 1.14003e+00\n",
      "\n",
      "Outer Cross Validation Fold: 2/3\n",
      "\n",
      "\tInner Fold: 1/3\n",
      "\n",
      "\tReplicate: 1/1\n",
      "\t\tIter\tLoss\t\t\tRel. loss\n",
      "\t\t1000\t0.15610085\t0.00034925627\n",
      "\t\t2000\t0.1363442\t0.00010545446\n",
      "\t\t3000\t0.119482666\t6.490942e-05\n",
      "\t\t4000\t0.11597585\t2.184198e-05\n",
      "\t\t5000\t0.11350293\t2.0348665e-05\n",
      "\t\t6000\t0.11174969\t9.3339995e-06\n",
      "\t\t7000\t0.111223\t1.6077039e-06\n",
      "\t\tFinal loss:\n",
      "\t\t7193\t0.11119481\t9.380656e-07\n",
      "\n",
      "\tBest loss: 0.11119481176137924\n",
      "\n",
      "\n",
      "\tReplicate: 1/1\n",
      "\t\tIter\tLoss\t\t\tRel. loss\n",
      "\t\t1000\t0.12857573\t0.00035010919\n",
      "\t\t2000\t0.10520631\t9.538377e-05\n",
      "\t\t3000\t0.097582944\t4.9625854e-05\n",
      "\t\t4000\t0.095143095\t1.0493324e-05\n",
      "\t\t5000\t0.094386406\t8.130446e-06\n",
      "\t\t6000\t0.09144198\t9.181815e-05\n",
      "\t\t7000\t0.08757147\t1.046473e-05\n",
      "\t\tFinal loss:\n",
      "\t\t7079\t0.08750377\t1.7029163e-07\n",
      "\n",
      "\tBest loss: 0.08750376850366592\n",
      "\n",
      "\n",
      "\tInner Fold: 2/3\n",
      "\n",
      "\tReplicate: 1/1\n",
      "\t\tIter\tLoss\t\t\tRel. loss\n",
      "\t\t1000\t0.2890043\t1.8664496e-05\n",
      "\t\t2000\t0.28474784\t1.6222371e-05\n",
      "\t\t3000\t0.2784899\t3.0926094e-05\n",
      "\t\t4000\t0.2681313\t2.734172e-05\n",
      "\t\t5000\t0.263146\t1.41565415e-05\n",
      "\t\t6000\t0.25986075\t1.032161e-05\n",
      "\t\t7000\t0.257953\t4.8524016e-06\n",
      "\t\t8000\t0.2564523\t3.2072934e-05\n",
      "\t\t9000\t0.2533491\t2.1173971e-06\n",
      "\t\tFinal loss:\n",
      "\t\t9744\t0.25305656\t9.4215443e-07\n",
      "\n",
      "\tBest loss: 0.2530565559864044\n",
      "\n",
      "\n",
      "\tReplicate: 1/1\n",
      "\t\tIter\tLoss\t\t\tRel. loss\n",
      "\t\t1000\t0.28343812\t0.00013614525\n",
      "\t\t2000\t0.26308474\t5.2559302e-05\n",
      "\t\t3000\t0.2502305\t5.3234635e-05\n",
      "\t\t4000\t0.22423032\t0.00013601429\n",
      "\t\t5000\t0.21116558\t1.8346886e-05\n",
      "\t\t6000\t0.20832115\t1.2088382e-05\n",
      "\t\t7000\t0.20560259\t1.5944368e-05\n",
      "\t\t8000\t0.20166497\t1.9876197e-05\n",
      "\t\t9000\t0.1983239\t1.2923135e-05\n",
      "\t\t10000\t0.19649677\t6.0666935e-06\n",
      "\t\tFinal loss:\n",
      "\t\t10314\t0.19617204\t6.076769e-07\n",
      "\n",
      "\tBest loss: 0.19617204368114471\n",
      "\n",
      "\n",
      "\tInner Fold: 3/3\n",
      "\n",
      "\tReplicate: 1/1\n",
      "\t\tIter\tLoss\t\t\tRel. loss\n",
      "\t\t1000\t0.109146096\t0.0011442697\n",
      "\t\t2000\t0.078349955\t0.000100979225\n",
      "\t\t3000\t0.07499797\t1.1225719e-05\n",
      "\t\t4000\t0.07453252\t4.89822e-06\n",
      "\t\t5000\t0.074182376\t4.7204694e-06\n",
      "\t\t6000\t0.07382818\t4.844033e-06\n",
      "\t\t7000\t0.07348242\t4.461259e-06\n",
      "\t\t8000\t0.07318683\t3.5630644e-06\n",
      "\t\t9000\t0.0729446\t3.268478e-06\n",
      "\t\t10000\t0.07269081\t4.0998584e-06\n",
      "\t\t11000\t0.0714155\t0.00014582819\n",
      "\t\t12000\t0.06282502\t2.4429473e-05\n",
      "\t\t13000\t0.061649293\t1.3052091e-05\n",
      "\t\t14000\t0.061094996\t5.7316524e-06\n",
      "\t\t15000\t0.06086397\t2.0810276e-06\n",
      "\t\tFinal loss:\n",
      "\t\t15000\t0.06086397\t2.0810276e-06\n",
      "\n",
      "\tBest loss: 0.06086397171020508\n",
      "\n",
      "\n",
      "\tReplicate: 1/1\n",
      "\t\tIter\tLoss\t\t\tRel. loss\n",
      "\t\t1000\t0.08503731\t0.000283881\n",
      "\t\t2000\t0.07159359\t0.00014432108\n",
      "\t\t3000\t0.06146637\t0.00013592295\n",
      "\t\t4000\t0.057110026\t3.854948e-05\n",
      "\t\t5000\t0.05495379\t6.03968e-05\n",
      "\t\t6000\t0.050031018\t5.4873726e-05\n",
      "\t\t7000\t0.048246\t2.7564813e-05\n",
      "\t\t8000\t0.04682425\t3.564116e-05\n",
      "\t\t9000\t0.045533877\t3.2069904e-05\n",
      "\t\t10000\t0.042446144\t5.8272635e-05\n",
      "\t\t11000\t0.04133076\t1.4060644e-05\n",
      "\t\t12000\t0.040385943\t2.2414364e-05\n",
      "\t\tFinal loss:\n",
      "\t\t12262\t0.040193\t9.268514e-07\n",
      "\n",
      "\tBest loss: 0.04019299894571304\n",
      "\n",
      "\tRetraining ANN using optimal number of hidden units\n",
      "\n",
      "\tReplicate: 1/1\n",
      "\t\tIter\tLoss\t\t\tRel. loss\n",
      "\t\t1000\t0.4087015\t0.00083488727\n",
      "\t\t2000\t0.3095798\t5.053763e-05\n",
      "\t\t3000\t0.29877988\t3.6605717e-05\n",
      "\t\t4000\t0.28665617\t5.1252315e-05\n",
      "\t\t5000\t0.27266663\t2.4045308e-05\n",
      "\t\t6000\t0.2703849\t3.5270864e-06\n",
      "\t\t7000\t0.26967186\t1.8787223e-06\n",
      "\t\tFinal loss:\n",
      "\t\t7690\t0.2693718\t9.957265e-07\n",
      "\n",
      "\tTest Error for Outer Fold 2/3\n",
      "\n",
      "\t\tRLR: 1.0299999713897705\n",
      "\n",
      "\t\tANN: 8.77217e-01\n",
      "\n",
      "Outer Cross Validation Fold: 3/3\n",
      "\n",
      "\tInner Fold: 1/3\n",
      "\n",
      "\tReplicate: 1/1\n",
      "\t\tIter\tLoss\t\t\tRel. loss\n",
      "\t\t1000\t0.1739218\t0.00024574794\n",
      "\t\t2000\t0.1507203\t9.697845e-05\n",
      "\t\t3000\t0.14138377\t3.7413873e-05\n",
      "\t\t4000\t0.13611028\t4.970081e-05\n",
      "\t\t5000\t0.1260651\t0.00013106895\n",
      "\t\t6000\t0.11727153\t2.941479e-05\n",
      "\t\t7000\t0.11565189\t6.6998923e-06\n",
      "\t\t8000\t0.115113266\t3.365632e-06\n",
      "\t\t9000\t0.11373696\t2.5940148e-05\n",
      "\t\t10000\t0.111973196\t7.4523086e-06\n",
      "\t\t11000\t0.11144234\t2.941652e-06\n",
      "\t\tFinal loss:\n",
      "\t\t11990\t0.11122845\t9.377819e-07\n",
      "\n",
      "\tBest loss: 0.11122845113277435\n",
      "\n",
      "\n",
      "\tReplicate: 1/1\n",
      "\t\tIter\tLoss\t\t\tRel. loss\n",
      "\t\t1000\t0.13197328\t0.0002504855\n",
      "\t\t2000\t0.11215803\t0.00016445192\n",
      "\t\t3000\t0.1011165\t5.651177e-05\n",
      "\t\t4000\t0.09628235\t5.0296174e-05\n",
      "\t\t5000\t0.09199121\t6.98105e-05\n",
      "\t\t6000\t0.082152836\t4.8699072e-05\n",
      "\t\t7000\t0.07985815\t1.8939072e-05\n",
      "\t\t8000\t0.07880241\t7.658299e-06\n",
      "\t\tFinal loss:\n",
      "\t\t8126\t0.07873184\t2.8389718e-07\n",
      "\n",
      "\tBest loss: 0.07873184233903885\n",
      "\n",
      "\n",
      "\tInner Fold: 2/3\n",
      "\n",
      "\tReplicate: 1/1\n",
      "\t\tIter\tLoss\t\t\tRel. loss\n",
      "\t\t1000\t0.30598167\t0.00013585322\n",
      "\t\t2000\t0.27650228\t5.3457647e-05\n",
      "\t\t3000\t0.264654\t3.7722464e-05\n",
      "\t\t4000\t0.25813097\t1.8472341e-05\n",
      "\t\t5000\t0.25451943\t1.0772396e-05\n",
      "\t\t6000\t0.25164822\t1.2316413e-05\n",
      "\t\t7000\t0.24812868\t1.8376237e-05\n",
      "\t\t8000\t0.24031088\t1.8664015e-05\n",
      "\t\t9000\t0.23859972\t3.4973307e-06\n",
      "\t\tFinal loss:\n",
      "\t\t9874\t0.23799028\t6.261244e-07\n",
      "\n",
      "\tBest loss: 0.23799027502536774\n",
      "\n",
      "\n",
      "\tReplicate: 1/1\n",
      "\t\tIter\tLoss\t\t\tRel. loss\n",
      "\t\t1000\t0.2629615\t0.00013518847\n",
      "\t\t2000\t0.23866905\t4.7697613e-05\n",
      "\t\t3000\t0.2291468\t3.719514e-05\n",
      "\t\t4000\t0.21632947\t7.114983e-05\n",
      "\t\t5000\t0.20616204\t2.6525646e-05\n",
      "\t\t6000\t0.20246658\t1.5013793e-05\n",
      "\t\t7000\t0.19947897\t1.3296497e-05\n",
      "\t\t8000\t0.1972576\t1.0349097e-05\n",
      "\t\t9000\t0.19396622\t3.541437e-05\n",
      "\t\t10000\t0.18964273\t1.3828993e-05\n",
      "\t\t11000\t0.18782102\t6.7436017e-06\n",
      "\t\t12000\t0.18687186\t3.827505e-06\n",
      "\t\t13000\t0.18630928\t2.2394568e-06\n",
      "\t\t14000\t0.18593945\t1.6829342e-06\n",
      "\t\tFinal loss:\n",
      "\t\t14934\t0.18569583\t9.62939e-07\n",
      "\n",
      "\tBest loss: 0.1856958270072937\n",
      "\n",
      "\n",
      "\tInner Fold: 3/3\n",
      "\n",
      "\tReplicate: 1/1\n",
      "\t\tIter\tLoss\t\t\tRel. loss\n",
      "\t\t1000\t0.1303262\t0.0006544961\n",
      "\t\t2000\t0.095160924\t0.00019906338\n",
      "\t\t3000\t0.07678801\t0.00013737266\n",
      "\t\t4000\t0.07119697\t4.7193767e-05\n",
      "\t\t5000\t0.06874053\t2.6879256e-05\n",
      "\t\t6000\t0.0671255\t2.1532525e-05\n",
      "\t\t7000\t0.06582197\t1.7770972e-05\n",
      "\t\t8000\t0.06479041\t1.3454247e-05\n",
      "\t\t9000\t0.064017184\t1.1172746e-05\n",
      "\t\t10000\t0.063115\t1.9949663e-05\n",
      "\t\t11000\t0.061638\t1.8977236e-05\n",
      "\t\t12000\t0.060947787\t5.928862e-06\n",
      "\t\t13000\t0.060723983\t2.1471728e-06\n",
      "\t\tFinal loss:\n",
      "\t\t13776\t0.060648456\t9.827882e-07\n",
      "\n",
      "\tBest loss: 0.06064845621585846\n",
      "\n",
      "\n",
      "\tReplicate: 1/1\n",
      "\t\tIter\tLoss\t\t\tRel. loss\n",
      "\t\t1000\t0.09873313\t0.0003627642\n",
      "\t\t2000\t0.08099173\t0.00010384803\n",
      "\t\t3000\t0.07087188\t0.00017637276\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t\t4000\t0.060432587\t0.00012351878\n",
      "\t\t5000\t0.054771155\t6.1006227e-05\n",
      "\t\t6000\t0.0521634\t4.3490323e-05\n",
      "\t\t7000\t0.04997565\t4.4425124e-05\n",
      "\t\t8000\t0.04738277\t8.663306e-05\n",
      "\t\t9000\t0.043500457\t5.257894e-05\n",
      "\t\t10000\t0.04188889\t4.8821646e-05\n",
      "\t\tFinal loss:\n",
      "\t\t10570\t0.04136031\t3.602767e-07\n",
      "\n",
      "\tBest loss: 0.04136031121015549\n",
      "\n",
      "\tRetraining ANN using optimal number of hidden units\n",
      "\n",
      "\tReplicate: 1/1\n",
      "\t\tIter\tLoss\t\t\tRel. loss\n",
      "\t\t1000\t0.23046035\t0.00011617736\n",
      "\t\t2000\t0.21927057\t1.8416244e-05\n",
      "\t\t3000\t0.21601212\t1.3244558e-05\n",
      "\t\t4000\t0.21343622\t1.1589243e-05\n",
      "\t\t5000\t0.21083081\t1.0460278e-05\n",
      "\t\t6000\t0.2089933\t9.625368e-06\n",
      "\t\t7000\t0.2062826\t1.784213e-05\n",
      "\t\t8000\t0.2016418\t2.2538738e-05\n",
      "\t\t9000\t0.19589706\t4.9668815e-05\n",
      "\t\t10000\t0.18647443\t1.1986348e-05\n",
      "\t\t11000\t0.1853308\t2.8945014e-06\n",
      "\t\tFinal loss:\n",
      "\t\t11266\t0.18520705\t4.827404e-07\n",
      "\n",
      "\tTest Error for Outer Fold 3/3\n",
      "\n",
      "\t\tRLR: 1.246999979019165\n",
      "\n",
      "\t\tANN: 1.32318e+00\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'Test mean-squared-error')"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1000x500 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1000x500 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Setup figure for display of ANN summaries\n",
    "summaries, summaries_axes = plt.subplots(1, 2, figsize=(10,5),num=2)\n",
    "color_list = ['tab:orange', 'tab:green', 'tab:purple', 'tab:brown', 'tab:pink',\n",
    "              'tab:gray', 'tab:olive', 'tab:cyan', 'tab:red', 'tab:blue']\n",
    "\n",
    "for k_out, (par_index, test_index) in enumerate(cv_outer.split(X,y)):\n",
    "    \n",
    "    print('\\nOuter Cross Validation Fold: {0}/{1}'.format(k_out+1,K_outer))\n",
    "    \n",
    "    # Split outer fold into parameterisation set and test set\n",
    "    X_par = X[par_index]\n",
    "    y_par = y[par_index]\n",
    "    X_test = X[test_index]\n",
    "    y_test = y[test_index]\n",
    "    y_par = y_par.squeeze()\n",
    "    \n",
    "    # Initialise\n",
    "    w = np.empty((M,K_inner,len(lambdas)))\n",
    "    train_error = np.empty((K_inner,len(lambdas)))\n",
    "    val_error = np.empty((K_inner,len(lambdas)))\n",
    "    test_error = np.empty((K_inner,len(lambdas)))\n",
    "    ann_val_error = np.empty((K_inner,len(h_values)))\n",
    "    ann_test_error = np.empty((K_inner,len(h_values)))\n",
    "    \n",
    "    # TODO: rename val_error, test_error, lambdas\n",
    "    \n",
    "    for k_in, (train_index, val_index) in enumerate(cv_inner.split(X_par,y_par)):\n",
    "    \n",
    "        print('\\n\\tInner Fold: {}/{}'.format(k_in+1,K_inner))\n",
    "        \n",
    "        # Split parameterisation set into training set and validation set\n",
    "        X_train = X[train_index]\n",
    "        y_train = y[train_index]\n",
    "        X_val = X[val_index]\n",
    "        y_val = y[val_index]\n",
    "    \n",
    "        ########################### Lingear Regression ###########################\n",
    "        # Standardize inner fold based on training set, and save the mean and std\n",
    "        mu[k_in, :] = np.mean(X_train[:, 1:], 0)\n",
    "        sigma[k_in, :] = np.std(X_train[:, 1:], 0)\n",
    "        X_train[:, 1:] = (X_train[:, 1:] - mu[k_in, :] ) / sigma[k_in, :]\n",
    "        X_val[:, 1:] = (X_val[:, 1:] - mu[k_in, :] ) / sigma[k_in, :]\n",
    "\n",
    "        # Precompute terms\n",
    "        Xty = X_train.T @ y_train\n",
    "        XtX = X_train.T @ X_train\n",
    "\n",
    "        # solve for weights\n",
    "        for l in range(0,len(lambdas)):\n",
    "            # Compute parameters for current value of lambda and current CV fold\n",
    "            lambdaI = lambdas[l] * np.eye(M)\n",
    "            lambdaI[0,0] = 0 # remove bias regularization\n",
    "            w[:,k_in,l] = np.linalg.solve(XtX+lambdaI,Xty).squeeze()\n",
    "            \n",
    "            # Evaluate training and test performance\n",
    "            train_error[k_in,l] = np.power(y_train-X_train @ w[:,k_in,l].T,2).mean(axis=0)\n",
    "            val_error[k_in,l] = np.power(y_test-X_test @ w[:,k_in,l].T,2).mean(axis=0)\n",
    "    \n",
    "        opt_val_err = np.min(np.mean(val_error,axis=0))\n",
    "        opt_lambda = lambdas[np.argmin(np.mean(val_error,axis=0))]\n",
    "        train_err_vs_lambda = np.mean(train_error,axis=0)\n",
    "        val_err_vs_lambda = np.mean(val_error,axis=0)\n",
    "        mean_w_vs_lambda = np.squeeze(np.mean(w,axis=1))\n",
    "        \n",
    "        \n",
    "        ############################### ANN ###############################\n",
    "        # Convert train and validation sets into tensors\n",
    "        X_train = torch.Tensor(X[train_index,:])\n",
    "        y_train = torch.Tensor(y[train_index]).reshape(-1,1)\n",
    "        X_val = torch.Tensor(X[val_index,:])\n",
    "        y_val = torch.Tensor(y[val_index]).reshape(-1,1)\n",
    "\n",
    "        # Train the net\n",
    "        for h in h_values:\n",
    "            net, final_loss, learning_curve = train_neural_net(model, \n",
    "                                                               h,\n",
    "                                                               loss_fn,\n",
    "                                                               X=X_train,\n",
    "                                                               y=y_train,\n",
    "                                                               n_replicates=n_replicates,\n",
    "                                                               max_iter=max_iter)\n",
    "            print('\\n\\tBest loss: {}\\n'.format(final_loss))\n",
    "\n",
    "            # Determine estimated values for validation set\n",
    "            y_val_est = net(X_val)\n",
    "\n",
    "            se_val = (y_val_est.squeeze().float()-y_val.squeeze().float())**2  # squared error\n",
    "            mse_val = (sum(se_val).type(torch.float)/len(y_val)).data.numpy()      # mean squared error\n",
    "        # TODO: ann_val_error is empty\n",
    "        opt_ann_val_err = np.min(np.mean(ann_val_error,axis=0))\n",
    "        opt_h = h_values[np.argmin(np.mean(ann_val_error,axis=0))]\n",
    "        \n",
    "        # TODO: Calculate mse using parameterisation set\n",
    "   \n",
    "    ########################### Lingear Regression ###########################\n",
    "    # Save optimal RLR hyperparameter from inner fold\n",
    "    opt_lambdas[k_out] = opt_lambda\n",
    "    \n",
    "    # Retrain linear regression model on parameterisation set using optimal lambda\n",
    "    Xty_par = X_par.T @ y_par\n",
    "    XtX_par = X_par.T @ X_par\n",
    "    \n",
    "    #### Estimate weights using parameterisation set\n",
    "    # for the optimal value of lambda\n",
    "    opt_lambda_I = opt_lambda * np.eye(M)\n",
    "    opt_lambda_I[0,0] = 0 # remove bias regularization\n",
    "    w_rlr[:,k_out] = np.linalg.solve(XtX_par+opt_lambda_I,Xty_par).squeeze()\n",
    "    \n",
    "    # for unregularized linear regression\n",
    "    w_noreg[:,k_out] = np.linalg.solve(XtX_par,Xty_par).squeeze()\n",
    "    \n",
    "    #### Compute mean squared error \n",
    "    # with regularization with optimal lambda\n",
    "    Error_par_rlr[k_out] = np.square(y_par-X_par @ w_rlr[:,k_out]).sum(axis=0)/y_par.shape[0]\n",
    "    Error_test_rlr[k_out] = np.square(y_test-X_test @ w_rlr[:,k_out]).sum(axis=0)/y_test.shape[0]\n",
    "    \n",
    "    # without using the input data\n",
    "    Error_par_nofeatures[k_out] = np.square(y_par-y_par.mean()).sum(axis=0)/y_par.shape[0]\n",
    "    Error_test_nofeatures[k_out] = np.square(y_test-y_test.mean()).sum(axis=0)/y_test.shape[0]\n",
    "\n",
    "    # without regularization\n",
    "    Error_par_lr[k_out] = np.square(y_par-X_par @ w_noreg[:,k_out]).sum(axis=0)/y_par.shape[0]\n",
    "    Error_test_lr[k_out] = np.square(y_test-X_test @ w_noreg[:,k_out]).sum(axis=0)/y_test.shape[0]\n",
    "\n",
    "    \n",
    "    \n",
    "    ##################################### ANN #####################################\n",
    "    # Convert test set into tensors\n",
    "    X_par = torch.Tensor(X[par_index])\n",
    "    y_par = torch.Tensor(y[par_index]).reshape(-1,1)\n",
    "    X_test = torch.Tensor(X[test_index])\n",
    "    y_test = torch.Tensor(y[test_index]).reshape(-1,1)\n",
    "    \n",
    "    # Save optimal ANN hyperparameter from inner fold\n",
    "    opt_h_values[k_out] = opt_h\n",
    "    \n",
    "    # Retrain ANN on parameterisation set using optimal number of hidden units\n",
    "    print(\"\\tRetraining ANN using optimal number of hidden units\")\n",
    "    opt_net, final_loss, learning_curve = train_neural_net(model,\n",
    "                                                           opt_h,\n",
    "                                                           loss_fn,\n",
    "                                                           X=X_par,\n",
    "                                                           y=y_par,\n",
    "                                                           n_replicates=n_replicates,\n",
    "                                                           max_iter=max_iter)\n",
    "    y_test_est = opt_net(X_test)\n",
    "    \n",
    "    # Determine ANN test error\n",
    "    se_test = (y_test_est.squeeze().float()-y_test.squeeze().float())**2     # squared error\n",
    "    mse_test = (sum(se_test).type(torch.float)/len(y_test)).data.numpy()\n",
    "    Error_test_ANN[k_out] = mse_test                     # store error rate for current CV fold\n",
    "    \n",
    "    print(\"\\n\\tTest Error for Outer Fold {}/{}\".format(k_out+1,K_outer))\n",
    "    print(\"\\n\\t\\tRLR: {}\".format(np.round(mse_test,3)))\n",
    "    print(\"\\n\\t\\tANN: {:.5e}\".format(Error_test_rlr[k_out][0]))\n",
    "    \n",
    "    \n",
    "    ############################### DISPLAY RESULTS ###############################\n",
    "    # Display the learning curve for the best net in the current outer fold\n",
    "#     h, = summaries_axes[0].plot(learning_curve, color=color_list[k_out])\n",
    "#     h.set_label('CV fold {0}'.format(k_out+1))\n",
    "#     summaries_axes[0].set_xlabel('Iterations')\n",
    "#     summaries_axes[0].set_ylabel('Loss')\n",
    "#     summaries_axes[0].set_title('Learning curves')\n",
    "\n",
    "   # Display the results for the last cross-validation fold\n",
    "    if k_out == K_outer-1:\n",
    "        reg_fig, reg_axes = plt.subplots(1, 2, figsize=(10,5),num=1)\n",
    "        reg_axes[0].semilogx(lambdas,mean_w_vs_lambda.T[:,1:],'-') # Don't plot the bias term\n",
    "        reg_axes[0].set_xlabel('Regularization factor')\n",
    "        reg_axes[0].set_ylabel('Mean Coefficient Values')\n",
    "        reg_axes[0].grid()\n",
    "        # TODO: add legend\n",
    "\n",
    "        reg_axes[1].set_title('Optimal lambda: 1e{0}'.format(round(np.log10(opt_lambdas[k_out][0]),5)))\n",
    "        reg_axes[1].loglog(lambdas,train_err_vs_lambda.T,'b-',lambdas,val_err_vs_lambda.T,'r-')\n",
    "        reg_axes[1].set_xlabel('Regularization factor')\n",
    "        reg_axes[1].set_ylabel('Squared error (crossvalidation)')\n",
    "        reg_axes[1].legend(['Train error','Validation error'])\n",
    "        reg_axes[1].grid()\n",
    "        reg_fig.tight_layout()\n",
    "\n",
    "# Display the MSE across folds\n",
    "summaries_axes[1].bar(np.arange(1, K_outer+1), np.squeeze(np.asarray(Error_test_ANN)), color=color_list)\n",
    "summaries_axes[1].set_xlabel('Fold')\n",
    "summaries_axes[1].set_xticks(np.arange(1, K_outer+1))\n",
    "summaries_axes[1].set_ylabel('MSE')\n",
    "summaries_axes[1].set_title('Test mean-squared-error')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6103de95",
   "metadata": {},
   "source": [
    "### Results of Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6f73aba",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Linear regression without feature selection:')\n",
    "print('- Training error: {0}'.format(Error_par_lr.mean()))\n",
    "print('- Test error:     {0}'.format(Error_test_lr.mean()))\n",
    "print('- R^2 train:     {0}'.format((Error_par_nofeatures.sum()-Error_par_lr.sum())/Error_par_nofeatures.sum()))\n",
    "print('- R^2 test:     {0}\\n'.format((Error_test_nofeatures.sum()-Error_test_lr.sum())/Error_test_nofeatures.sum()))\n",
    "\n",
    "print('Regularized linear regression:')\n",
    "print('- Training error: {0}'.format(Error_par_rlr.mean()))\n",
    "print('- Test error:     {0}'.format(Error_test_rlr.mean()))\n",
    "print('- R^2 train:     {0}'.format((Error_par_nofeatures.sum()-Error_par_rlr.sum())/Error_par_nofeatures.sum()))\n",
    "print('- R^2 test:     {0}\\n'.format((Error_test_nofeatures.sum()-Error_test_rlr.sum())/Error_test_nofeatures.sum()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fc0087c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bar plot of RLR weights\n",
    "weights = range(1,M)      # skip offset\n",
    "bw = 1.0/(len(weights)+1)\n",
    "r = np.arange(1,K_outer+1)\n",
    "\n",
    "plt.figure(figsize=(6,6), num=3)\n",
    "for i in weights:\n",
    "    plt.bar(r+i*bw, w_rlr[i,:], width=bw)\n",
    "plt.xticks(r+bw, range(1,K_outer+1))\n",
    "plt.xlabel('Attributes')\n",
    "plt.ylabel('Weights')\n",
    "plt.legend(attribute_names[1:M+1], loc=(1.04, 0))\n",
    "plt.grid()\n",
    "plt.title('Weights from each fold of Regularized Linear Regression')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79fa5469",
   "metadata": {},
   "source": [
    "### Results of ANN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de5b13e6",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# plt.figure(figsize=(5,5),num=5)\n",
    "# y_est = y_test_est.data.numpy().squeeze()\n",
    "# y_true = y_test.data.numpy().squeeze()\n",
    "# axis_range = [np.min([y_est, y_true])-1,np.max([y_est, y_true])+1]\n",
    "# plt.plot(axis_range,axis_range,'k--')           # perfect estimation\n",
    "# plt.plot(y_true, y_est,'ob',alpha=.25)          # ANN estimation\n",
    "# plt.legend(['Perfect estimation','Model estimations'])\n",
    "# plt.title('cnt: estimated VS true value (for last CV-fold)')\n",
    "# plt.ylim(axis_range)\n",
    "# plt.xlim(axis_range)\n",
    "# plt.xlabel('True value')\n",
    "# plt.ylabel('Estimated value')\n",
    "# plt.grid()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a387ad6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# # Diagram of best neural net in last fold\n",
    "# weights = [net[i].weight.data.numpy().T for i in [0,2]]\n",
    "# biases = [net[i].bias.data.numpy() for i in [0,2]]\n",
    "# tf =  [str(net[i]) for i in [1,2]]\n",
    "# draw_neural_net(weights, biases, tf, attribute_names=attribute_names)\n",
    "\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7016d51",
   "metadata": {},
   "source": [
    "### Table 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f24c20db",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(\"Outer fold \\tANN \\t\\t\\tLinear Regression \\t\\tBaseline\")\n",
    "print(\"--------------------------------------------------------------------------------\")\n",
    "print(\"i \\t\\thâˆ—_i \\tEtest_i \\tlambda_i \\tEtest_i \\tEtest_i\")\n",
    "for i in range(K_outer):\n",
    "    print(\"{} \\t\\t{:.3f} \\t{:.3f} \\t\\t{:.2e} \\t{:.2f} \\t\\t{:.3f}\".format(\\\n",
    "        i+1,opt_h_values[i][0],Error_test_ANN[i].item(),opt_lambdas[i][0],\\\n",
    "            Error_test_rlr[i][0],Error_test_nofeatures[i][0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d5cd3b0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53033645",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3984005",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9539e70",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "raw",
   "id": "41f43467",
   "metadata": {},
   "source": [
    "Test values for Reg Lin Regression only\n",
    "\n",
    "\n",
    "K_outer = 4, K_inner = 4\n",
    "# Outer fold \tANN \t\t\tLinear Regression \t\tBaseline\n",
    "--------------------------------------------------------------------------------\n",
    "i \t\thâˆ—_i \tEtest_i \tlambda_i \tEtest_i \tEtest_i\n",
    "1 \t\t0.000 \t0.581 \t\t1.63e+02 \t0.93 \t\t0.581\n",
    "2 \t\t0.000 \t0.307 \t\t4.33e+02 \t0.67 \t\t0.307\n",
    "3 \t\t0.000 \t0.773 \t\t1.00e-05 \t1.18 \t\t0.773\n",
    "4 \t\t0.000 \t0.817 \t\t1.00e-05 \t1.39 \t\t0.817\n",
    "\n",
    "\n",
    "K_outer = 5, K_inner = 5\n",
    "Outer fold \tANN \t\t\tLinear Regression \t\tBaseline\n",
    "--------------------------------------------------------------------------------\n",
    "i \t\thâˆ—_i \tEtest_i \tlambda_i \tEtest_i \tEtest_i\n",
    "1 \t\t0.000 \t0.000 \t\t1.18e+02 \t0.95 \t\t0.434\n",
    "2 \t\t0.000 \t0.000 \t\t3.05e+03 \t0.26 \t\t0.173\n",
    "3 \t\t0.000 \t0.000 \t\t6.14e+01 \t0.27 \t\t0.272\n",
    "4 \t\t0.000 \t0.000 \t\t1.00e-05 \t1.13 \t\t0.327\n",
    "5 \t\t0.000 \t0.000 \t\t1.00e-05 \t1.31 \t\t0.941\n",
    "\n",
    "\n",
    "K_outer = 10, K_inner = 10\n",
    "Outer fold \tANN \t\t\tLinear Regression \t\tBaseline\n",
    "--------------------------------------------------------------------------------\n",
    "i \t\thâˆ—_i \tEtest_i \tlambda_i \tEtest_i \tEtest_i\n",
    "1 \t\t0.000 \t0.000 \t\t6.14e+01 \t0.90 \t\t0.063\n",
    "2 \t\t0.000 \t0.000 \t\t1.63e+02 \t0.54 \t\t0.335\n",
    "3 \t\t0.000 \t0.000 \t\t2.98e+04 \t0.09 \t\t0.086\n",
    "4 \t\t0.000 \t0.000 \t\t1.12e+04 \t0.26 \t\t0.245\n",
    "5 \t\t0.000 \t0.000 \t\t8.50e+01 \t0.34 \t\t0.245\n",
    "6 \t\t0.000 \t0.000 \t\t1.67e+01 \t0.44 \t\t0.275\n",
    "7 \t\t0.000 \t0.000 \t\t1.00e-05 \t1.03 \t\t0.394\n",
    "8 \t\t0.000 \t0.000 \t\t1.00e-05 \t0.50 \t\t0.200\n",
    "9 \t\t0.000 \t0.000 \t\t1.00e-05 \t1.31 \t\t0.275\n",
    "10 \t\t0.000 \t0.000 \t\t1.00e-05 \t0.59 \t\t0.924"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "course02450",
   "language": "python",
   "name": "course02450"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ffe290b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pylab as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.io import loadmat\n",
    "import sklearn.linear_model as lm\n",
    "from sklearn import model_selection\n",
    "from toolbox_02450 import rlr_validate, train_neural_net, draw_neural_net, visualize_decision_boundary\n",
    "import torch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e59cb38",
   "metadata": {},
   "source": [
    "## Load and Prepare Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "903f19d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read file and store as pandas dataframe\n",
    "filename = '../Data/day.csv'\n",
    "df = pd.read_csv(filename)\n",
    "df = df.drop('instant', axis=1)\n",
    "df = df.drop('dteday', axis=1)\n",
    "N, M = df.shape\n",
    "attributeNames = list(df.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2c0a4a1",
   "metadata": {},
   "source": [
    "### Standardize Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cab2c2c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Undo the original max-min normalization\n",
    "temp = df.columns.get_loc(\"temp\")\n",
    "atemp = df.columns.get_loc(\"atemp\")\n",
    "hum = df.columns.get_loc(\"hum\")\n",
    "windspeed = df.columns.get_loc(\"windspeed\")\n",
    "\n",
    "X = df.values\n",
    "for row in range(0, N):\n",
    "    X[row, temp] = X[row, temp]*(39-(-8)) + (-8)\n",
    "    X[row, atemp] = X[row, atemp]*(50-(-16)) + (-16)\n",
    "    X[row, hum] = X[row, hum]*100\n",
    "    X[row, windspeed] = X[row, windspeed]*67\n",
    "    \n",
    "# Standarize ratio data attributesPCA\n",
    "temp_col = df.columns.get_loc(\"temp\")\n",
    "cnt_col = df.columns.get_loc(\"cnt\")\n",
    "\n",
    "for col in range(temp_col, cnt_col+1):\n",
    "    # subtract mean, column by column\n",
    "    mn = X[:, col].mean(0)\n",
    "    X[:, col] = X[:, col] - np.ones(N) * mn\n",
    "    X[:, col] = X[:, col] * (1/np.std(X[:, col]))\n",
    "    \n",
    "# Focus on the last 7 attributes\n",
    "attributeNames = attributeNames[temp_col:cnt_col+1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f4187bd",
   "metadata": {},
   "source": [
    "### Set 'cnt' as target variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8e00221b",
   "metadata": {},
   "outputs": [],
   "source": [
    "cnt_col = attributeNames.index(\"cnt\")\n",
    "# Split dataset into features and target vector\n",
    "y = X[:,cnt_col]\n",
    "X = X[:,0:cnt_col]\n",
    "N, M = X.shape\n",
    "\n",
    "# Add offset attribute\n",
    "X = np.concatenate((np.ones((X.shape[0],1)),X),1)\n",
    "attributeNames = [u'Offset']+attributeNames\n",
    "M = M+1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4b9dc56",
   "metadata": {},
   "source": [
    "## Regularized Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4ddf27cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cross validation\n",
    "K = 10\n",
    "CV = model_selection.KFold(K, shuffle=False)\n",
    "\n",
    "# Values of lambda\n",
    "lambdas = np.power(10.,np.linspace(-5,9,100))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef14c21f",
   "metadata": {},
   "source": [
    "## Artificial Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fb0fc087",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1000x500 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Setup figure for display of the decision boundary\n",
    "decision_boundaries = plt.figure(1, figsize=(10,10))\n",
    "subplot_size_1 = int(np.floor(np.sqrt(K))) \n",
    "subplot_size_2 = int(np.ceil(K/subplot_size_1))\n",
    "plt.suptitle('Data and model decision boundaries', fontsize=20)\n",
    "plt.subplots_adjust(left=0, bottom=0, right=1, top=.9, wspace=.5, hspace=0.25)\n",
    "summaries, summaries_axes = plt.subplots(1, 2, figsize=(10,5))\n",
    "color_list = ['tab:orange', 'tab:green', 'tab:purple', 'tab:brown', 'tab:pink',\n",
    "              'tab:gray', 'tab:olive', 'tab:cyan', 'tab:red', 'tab:blue']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "23525c83",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model of type:\n",
      "\n",
      "Sequential(\n",
      "  (0): Linear(in_features=7, out_features=5, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=5, out_features=1, bias=True)\n",
      "  (3): Sigmoid()\n",
      ")\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Define the ANN model structure\n",
    "n_hidden_units = 5\n",
    "n_replicates = 1        # number of networks trained in each k-fold\n",
    "max_iter = 10000\n",
    "\n",
    "model = lambda: torch.nn.Sequential(\n",
    "                    torch.nn.Linear(M, n_hidden_units), #M features to H hiden units\n",
    "                    # 1st transfer function, either Tanh or ReLU:\n",
    "                    torch.nn.Tanh(),                            #torch.nn.ReLU(),\n",
    "                    torch.nn.Linear(n_hidden_units, 1), # H hidden units to 1 output neuron\n",
    "                    torch.nn.Sigmoid() # final tranfer function\n",
    "                    )\n",
    "loss_fn = torch.nn.MSELoss()\n",
    "print('Training model of type:\\n\\n{}\\n'.format(str(model())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5785d5da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize variables\n",
    "Error_train = np.empty((K,1))\n",
    "Error_test = np.empty((K,1))\n",
    "Error_train_rlr = np.empty((K,1))\n",
    "Error_test_rlr = np.empty((K,1))\n",
    "Error_train_nofeatures = np.empty((K,1))\n",
    "Error_test_nofeatures = np.empty((K,1))\n",
    "Error_train_ANN = np.empty((K,1))\n",
    "Error_test_ANN = np.zeros((K,1))\n",
    "Errors_ANN = []\n",
    "opt_h = np.zeros((K,1))                   # optimal ANN hidden units for each outer fold\n",
    "opt_lambdas = np.empty((K,1))             # optimal lambdas for each outer fold\n",
    "w_rlr = np.empty((M,K))                   # weights for each attribute with regularisation\n",
    "w_noreg = np.empty((M,K))                 # weights for each attribute without regularisation\n",
    "mu = np.empty((K, M-1))\n",
    "sigma = np.empty((K, M-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "636b59c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Crossvalidation fold: 1/10\n",
      "\n",
      "\tReplicate: 1/1\n",
      "\t\tIter\tLoss\t\t\tRel. loss\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\yufan\\anaconda3\\envs\\course02450\\lib\\site-packages\\torch\\nn\\modules\\loss.py:536: UserWarning: Using a target size (torch.Size([657])) that is different to the input size (torch.Size([657, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t\t1000\t0.46106562\t3.328742e-05\n",
      "\t\t2000\t0.45341027\t8.150362e-06\n",
      "\t\t3000\t0.45110068\t3.2372131e-06\n",
      "\t\t4000\t0.45012292\t1.3903933e-06\n",
      "\t\tFinal loss:\n",
      "\t\t4310\t0.44993767\t9.935474e-07\n",
      "\n",
      "\tBest loss: 0.4499376714229584\n",
      "\n",
      "\n",
      "Crossvalidation fold: 2/10\n",
      "\n",
      "\tReplicate: 1/1\n",
      "\t\tIter\tLoss\t\t\tRel. loss\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\yufan\\anaconda3\\envs\\course02450\\lib\\site-packages\\torch\\nn\\modules\\loss.py:536: UserWarning: Using a target size (torch.Size([658])) that is different to the input size (torch.Size([658, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t\t1000\t0.44484577\t1.3063802e-05\n",
      "\t\t2000\t0.44212916\t2.8984655e-06\n",
      "\t\tFinal loss:\n",
      "\t\t2819\t0.44147074\t9.4509574e-07\n",
      "\n",
      "\tBest loss: 0.441470742225647\n",
      "\n",
      "\n",
      "Crossvalidation fold: 3/10\n",
      "\n",
      "\tReplicate: 1/1\n",
      "\t\tIter\tLoss\t\t\tRel. loss\n",
      "\t\t1000\t0.48710206\t1.982287e-05\n",
      "\t\t2000\t0.48196396\t5.3796307e-06\n",
      "\t\t3000\t0.4802908\t2.1717656e-06\n",
      "\t\tFinal loss:\n",
      "\t\t3877\t0.47962803\t9.941801e-07\n",
      "\n",
      "\tBest loss: 0.4796280264854431\n",
      "\n",
      "\n",
      "Crossvalidation fold: 4/10\n",
      "\n",
      "\tReplicate: 1/1\n",
      "\t\tIter\tLoss\t\t\tRel. loss\n",
      "\t\t1000\t0.43735048\t1.8807083e-05\n",
      "\t\t2000\t0.433091\t4.9545165e-06\n",
      "\t\t3000\t0.43163222\t2.2094555e-06\n",
      "\t\tFinal loss:\n",
      "\t\t3913\t0.43098673\t9.680857e-07\n",
      "\n",
      "\tBest loss: 0.4309867322444916\n",
      "\n",
      "\n",
      "Crossvalidation fold: 5/10\n",
      "\n",
      "\tReplicate: 1/1\n",
      "\t\tIter\tLoss\t\t\tRel. loss\n",
      "\t\t1000\t0.4606844\t6.824478e-05\n",
      "\t\t2000\t0.44561106\t1.531521e-05\n",
      "\t\t3000\t0.44138998\t5.739104e-06\n",
      "\t\t4000\t0.4396466\t2.6436858e-06\n",
      "\t\t5000\t0.43879053\t1.4942212e-06\n",
      "\t\tFinal loss:\n",
      "\t\t5320\t0.43861276\t9.512539e-07\n",
      "\n",
      "\tBest loss: 0.43861275911331177\n",
      "\n",
      "\n",
      "Crossvalidation fold: 6/10\n",
      "\n",
      "\tReplicate: 1/1\n",
      "\t\tIter\tLoss\t\t\tRel. loss\n",
      "\t\t1000\t0.4964993\t0.00010923339\n",
      "\t\t2000\t0.47206494\t2.215878e-05\n",
      "\t\t3000\t0.46576968\t7.870106e-06\n",
      "\t\t4000\t0.46324936\t3.66698e-06\n",
      "\t\t5000\t0.46203077\t1.8705805e-06\n",
      "\t\tFinal loss:\n",
      "\t\t5798\t0.46148342\t9.686901e-07\n",
      "\n",
      "\tBest loss: 0.4614834189414978\n",
      "\n",
      "\n",
      "Crossvalidation fold: 7/10\n",
      "\n",
      "\tReplicate: 1/1\n",
      "\t\tIter\tLoss\t\t\tRel. loss\n",
      "\t\t1000\t0.46991357\t2.7523894e-05\n",
      "\t\t2000\t0.46216992\t9.672428e-06\n",
      "\t\t3000\t0.4591424\t4.348862e-06\n",
      "\t\t4000\t0.45770893\t2.2789131e-06\n",
      "\t\t5000\t0.45695516\t1.3043855e-06\n",
      "\t\tFinal loss:\n",
      "\t\t5044\t0.4569313\t9.783405e-07\n",
      "\n",
      "\tBest loss: 0.45693129301071167\n",
      "\n",
      "\n",
      "Crossvalidation fold: 8/10\n",
      "\n",
      "\tReplicate: 1/1\n",
      "\t\tIter\tLoss\t\t\tRel. loss\n",
      "\t\t1000\t0.48283\t2.5861795e-05\n",
      "\t\t2000\t0.47708514\t5.434644e-06\n"
     ]
    }
   ],
   "source": [
    "for k, (train_index, test_index) in enumerate(CV.split(X,y)):\n",
    "    print('\\nCrossvalidation fold: {0}/{1}'.format(k+1,K))    \n",
    "    internal_cross_validation = 10    \n",
    "    \n",
    "    ############################### Lingear Regression ############################### \n",
    "    # Extract training and test set for current CV fold\n",
    "    X_train = X[train_index]\n",
    "    y_train = y[train_index]\n",
    "    X_test = X[test_index]\n",
    "    y_test = y[test_index]\n",
    "    \n",
    "    opt_val_err,opt_lambdas[k],mean_w_vs_lambda,train_err_vs_lambda,test_err_vs_lambda = \\\n",
    "    rlr_validate(X_train, y_train, lambdas, internal_cross_validation)\n",
    "\n",
    "    # Standardize outer fold based on training set, and save the mean and std\n",
    "    mu[k, :] = np.mean(X_train[:, 1:], 0)\n",
    "    sigma[k, :] = np.std(X_train[:, 1:], 0)\n",
    "    \n",
    "    X_train[:, 1:] = (X_train[:, 1:] - mu[k, :] ) / sigma[k, :] \n",
    "    X_test[:, 1:] = (X_test[:, 1:] - mu[k, :] ) / sigma[k, :] \n",
    "    \n",
    "    Xty = X_train.T @ y_train\n",
    "    XtX = X_train.T @ X_train\n",
    "    \n",
    "    # Compute mean squared error without using the input data at all\n",
    "    Error_train_nofeatures[k] = np.square(y_train-y_train.mean()).sum(axis=0)/y_train.shape[0]\n",
    "    Error_test_nofeatures[k] = np.square(y_test-y_test.mean()).sum(axis=0)/y_test.shape[0]\n",
    "\n",
    "    # Estimate weights for the optimal value of lambda, on entire training set\n",
    "    lambdaI = opt_lambdas[k] * np.eye(M)\n",
    "    lambdaI[0,0] = 0 # Do no regularize the bias term\n",
    "    w_rlr[:,k] = np.linalg.solve(XtX+lambdaI,Xty).squeeze()\n",
    "    \n",
    "    # Compute mean squared error with regularization with optimal lambda\n",
    "    Error_train_rlr[k] = np.square(y_train-X_train @ w_rlr[:,k]).sum(axis=0)/y_train.shape[0]\n",
    "    Error_test_rlr[k] = np.square(y_test-X_test @ w_rlr[:,k]).sum(axis=0)/y_test.shape[0]\n",
    "\n",
    "    # Estimate weights for unregularized linear regression, on entire training set\n",
    "    w_noreg[:,k] = np.linalg.solve(XtX,Xty).squeeze()\n",
    "    \n",
    "    # Compute mean squared error without regularization\n",
    "    Error_train[k] = np.square(y_train-X_train @ w_noreg[:,k]).sum(axis=0)/y_train.shape[0]\n",
    "    Error_test[k] = np.square(y_test-X_test @ w_noreg[:,k]).sum(axis=0)/y_test.shape[0]\n",
    "    \n",
    "    ##################################### ANN ##################################### \n",
    "    # Extract test and train tensor sets to train ANN\n",
    "    X_train = torch.Tensor(X[train_index,:])\n",
    "    y_train = torch.Tensor(y[train_index])\n",
    "    X_test = torch.Tensor(X[test_index,:])\n",
    "    y_test = torch.Tensor(y[test_index])\n",
    "    \n",
    "    # Train the net on training data\n",
    "    net, final_loss, learning_curve = train_neural_net(model,\n",
    "                                                       loss_fn,\n",
    "                                                       X=X_train,\n",
    "                                                       y=y_train,\n",
    "                                                       n_replicates=n_replicates,\n",
    "                                                       max_iter=max_iter)\n",
    "    print('\\n\\tBest loss: {}\\n'.format(final_loss))\n",
    "    \n",
    "    # Determine estimated class labels for test set\n",
    "    y_test_est = net(X_test)\n",
    "    # Determine errors\n",
    "    se = (y_test_est.float()-y_test.float())**2 # squared error\n",
    "    mse = (sum(se).type(torch.float)/len(y_test)).data.numpy() #mean\n",
    "    Errors_ANN.append(mse) # store error rate for current CV fold \n",
    "    \n",
    "    # Display the learning curve for the best net in the current fold\n",
    "    h, = summaries_axes[0].plot(learning_curve, color=color_list[k])\n",
    "    h.set_label('CV fold {0}'.format(k+1))\n",
    "    summaries_axes[0].set_xlabel('Iterations')\n",
    "    summaries_axes[0].set_xlim((0, max_iter))\n",
    "    summaries_axes[0].set_ylabel('Loss')\n",
    "    summaries_axes[0].set_title('Learning curves')\n",
    "    \n",
    "    # Display the results for the last cross-validation fold\n",
    "    if k == K-1:\n",
    "        plt.figure(k, figsize=(12,8))\n",
    "        plt.subplot(1,2,1)\n",
    "        plt.semilogx(lambdas,mean_w_vs_lambda.T[:,1:],'-') # Don't plot the bias term\n",
    "        plt.xlabel('Regularization factor')\n",
    "        plt.ylabel('Mean Coefficient Values')\n",
    "        plt.grid()\n",
    "        \n",
    "        plt.subplot(1,2,2)\n",
    "        plt.title('Optimal lambda: 1e{0}'.format(round(np.log10(opt_lambdas[k][0]),5)))\n",
    "        plt.loglog(lambdas,train_err_vs_lambda.T,'b-',lambdas,test_err_vs_lambda.T,'r-')\n",
    "        plt.xlabel('Regularization factor')\n",
    "        plt.ylabel('Squared error (crossvalidation)')\n",
    "        plt.legend(['Train error','Validation error'])\n",
    "        plt.grid()\n",
    "        \n",
    "        plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71e5e128",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display the MSE across folds\n",
    "summaries_axes[1].bar(np.arange(1, K+1), np.squeeze(np.asarray(Errors_ANN)), color=color_list)\n",
    "summaries_axes[1].set_xlabel('Fold')\n",
    "summaries_axes[1].set_xticks(np.arange(1, K+1))\n",
    "summaries_axes[1].set_ylabel('MSE')\n",
    "summaries_axes[1].set_title('Test mean-squared-error')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34032ad0",
   "metadata": {},
   "source": [
    "### Display Linear Regression Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8730f2bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Linear regression without feature selection:')\n",
    "print('- Training error: {0}'.format(Error_train.mean()))\n",
    "print('- Test error:     {0}'.format(Error_test.mean()))\n",
    "print('- R^2 train:     {0}'.format((Error_train_nofeatures.sum()-Error_train.sum())/Error_train_nofeatures.sum()))\n",
    "print('- R^2 test:     {0}\\n'.format((Error_test_nofeatures.sum()-Error_test.sum())/Error_test_nofeatures.sum()))\n",
    "print('Regularized linear regression:')\n",
    "print('- Training error: {0}'.format(Error_train_rlr.mean()))\n",
    "print('- Test error:     {0}'.format(Error_test_rlr.mean()))\n",
    "print('- R^2 train:     {0}'.format((Error_train_nofeatures.sum()-Error_train_rlr.sum())/Error_train_nofeatures.sum()))\n",
    "print('- R^2 test:     {0}\\n'.format((Error_test_nofeatures.sum()-Error_test_rlr.sum())/Error_test_nofeatures.sum()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cc25221",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show weight values in text form\n",
    "# for fold in range(K):\n",
    "#     print('Weights in fold {}/{}:'.format(fold+1, K))\n",
    "#     for m in range(M):\n",
    "#         print('{:>15} {:>15}'.format(attributeNames[m], np.round(w_rlr[m,fold],5)))        \n",
    "#     print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4539ffa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bar plot of RLR weights\n",
    "weights = [1,2,3,4,5,6]      # skip offset\n",
    "bw = .15\n",
    "r = np.arange(1,K+1)\n",
    "\n",
    "for i in weights:    \n",
    "    plt.bar(r+i*bw, w_rlr[i,:], width=bw)\n",
    "    \n",
    "plt.xticks(r+bw, range(1,K+1))\n",
    "plt.xlabel('Attributes')\n",
    "plt.ylabel('Weights')\n",
    "plt.legend(attributeNames[1:M+1], loc=(1.04, 0))\n",
    "plt.grid()\n",
    "plt.title('Weights from each fold of Regularized Linear Regression')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f3a11d7",
   "metadata": {},
   "source": [
    "### Display ANN Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efca8a3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Diagram of best neural net in last fold:')\n",
    "weights = [net[i].weight.data.numpy().T for i in [0,2]]\n",
    "biases = [net[i].bias.data.numpy() for i in [0,2]]\n",
    "tf =  [str(net[i]) for i in [1,2]]\n",
    "draw_neural_net(weights, biases, tf, attribute_names=attributeNames)\n",
    "\n",
    "# Print the average classification error rate\n",
    "print('\\nEstimated generalization error, RMSE: {0}'.format(round(np.sqrt(np.mean(errors)), 4)))\n",
    "\n",
    "# When dealing with regression outputs, a simple way of looking at the quality\n",
    "# of predictions visually is by plotting the estimated value as a function of \n",
    "# the true/known value - these values should all be along a straight line \"y=x\", \n",
    "# and if the points are above the line, the model overestimates, whereas if the\n",
    "# points are below the y=x line, then the model underestimates the value\n",
    "plt.figure(figsize=(10,10))\n",
    "y_est = y_test_est.data.numpy(); y_true = y_test.data.numpy()\n",
    "axis_range = [np.min([y_est, y_true])-1,np.max([y_est, y_true])+1]\n",
    "plt.plot(axis_range,axis_range,'k--')\n",
    "plt.plot(y_true, y_est,'ob',alpha=.25)\n",
    "plt.legend(['Perfect estimation','Model estimations'])\n",
    "plt.title('cnt: estimated versus true value (for last CV-fold)')\n",
    "plt.ylim(axis_range); plt.xlim(axis_range)\n",
    "plt.xlabel('True value')\n",
    "plt.ylabel('Estimated value')\n",
    "plt.grid()\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fde52941",
   "metadata": {},
   "source": [
    "### Table 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0eb04aca",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Outer fold \\tANN \\t\\t\\tLinear Regression \\t\\tBaseline\")\n",
    "print(\"i \\t\\thâˆ—_i \\tEtest_i \\tlambda_i \\tEtest_i \\tEtest_i\")\n",
    "for i in range(K):\n",
    "    print(\"{} \\t\\t{:.3f} \\t{:.3f} \\t\\t{:.2e} \\t{:.3f} \\t\\t{:.3f}\".format(\\\n",
    "        i+1,opt_h[i][0],Error_test_ANN[i][0],opt_lambdas[i][0],Error_test_rlr[i][0],Error_test_nofeatures[i][0]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "course02450",
   "language": "python",
   "name": "course02450"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
